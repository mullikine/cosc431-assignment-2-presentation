* Plan
4 Page report on the topic of your choice. 

** Remember
M-x academic-phrases
Use this when writing the report.

** Look for 2 other papers on the same topic

** Related papers
*** Outrageously large neural networks

Under review as a conference paper at ICLR 2017

[[/home/shane/dump/home/shane/notes2018/projects/ir-assignment-2/1701.06538.pdf][1701.06538.pdf]]

Don't have to go into too much detail.

Language modelling.

The capacity of a neural network to absorb information is limited by its number of
parameters.

Conditional computation, where parts of the network are active on a
per-example basis, has been proposed in theory as a way of dramatically increasing
model capacity without a proportional increase in computation. In practice,
however, there are significant algorithmic and performance challenges. In this
work, we address these challenges and finally realize the promise of conditional
computation, achieving greater than 1000x improvements in model capacity with
only minor losses in computational efficiency on modern GPU clusters.

We introduce
a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to
thousands of feed-forward sub-networks. A trainable gating network determines
a sparse combination of these experts to use for each example. We apply the MoE
to the tasks of language modeling and machine translation, where model capacity
is critical for absorbing the vast quantities of knowledge available in the training
corpora.

We present model architectures in which a MoE with up to 137 billion
parameters is applied convolutionally between stacked LSTM layers. On large
language modeling and machine translation benchmarks, these models achieve
significantly better results than state-of-the-art at lower computational cost

** Write it all out here before putting into latex

** 
[[https://news.ycombinator.com/item?id=15892956][Machine Learning for Systems and Systems for Machine Learning  pdf  | Hacker News]]

** I have to write a report
Andrew wanted something from one of the journals he asked me to go looking through

Here is a different kind of The Great Convergence: when neural networks go after data structures, (hashes, etc....) and eventually database systems....

The Case for Learned Index Structures by Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis

Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.


~2X space improvement over
Bloom Filter at same false positive rate


** research questions per paper
** main contribution of each paper

* Criticism
https://dawn.cs.stanford.edu/2018/01/11/index-baselines/

* Commentry
https://news.ycombinator.com/item?id=12815231

* Article / Charts
https://arstechnica.com/information-technology/2016/10/google-ai-neural-network-cryptography/

* Contribution
What is new?

* [New] Network / algorithm / technique
** How does it work?
** Is it suited to the task?
** Has it been well tested
** Does it really work as claimed?
** What are the limitations?

* Which kind of network was chosen
** Why was it chosen?
** Was it the right one?
** Is it clearly described
*** Parameters
*** Settings

* What strengths and/or weaknesses of the NN approach does it illustrate?

* Own questions / Additional relevant information

https://news.ycombinator.com/item?id=15894896

* Assignment 2 minimum structure
** Title
Report on neural networks with information retrieval

** Abstract
This report is an investigation into the growing role of neural networks in information retrieval.
I've tried to take an unbiased approach. After reading 'The Case for Learned Indexes', I wanted to make a case for Classical Data Structures too so I researched other opinions.
I will quickly go over some of the applications of deep learning to IR.
Then I'll go into depth with "The case for learned index structures", where I'll acknowledge some of the benefits of learned indexes.
Finally, I will review some examples of standard data structures and show that they still have a place.

** Introduction
Machine learning plays a role in many aspects of modern IR systems, and deep learning is applied in all of them, such as in semantic matching, learning to rank, modelling user behaviour and learning to index.

Neural networks are going after the data structures now, (B-trees, hashes, etc.). Deep learning has its tendrils all over modern IR systems.

It is interesting to see what key insights into IR problems the new technologies are able to give us and to clarify what is the best tool for the job.

#+BEGIN_COMMENT
I'll briefly cover some of the methods in IR and how they benefit IR research. It covers key architectures, as well as the most promising future directions.
#+END_COMMENT

** Conclusion
Standard data structures and show that they still have a place.

** Neural networks in information retrieval

** References
*** The tutorial
Gives a clear overview of current tried-and-trusted neural methods in IR and how they benefit IR research. It covers key architectures, as well as the most promising future directions.

Key architectures
**** promising future directions
***** 
cite:Memaccess

NIPS
https://arxiv.org/pdf/1706.03762.pdfw
****** commentary
https://news.ycombinator.com/item?id=15938082

Neural Networks for Information Retrieval
https://arxiv.org/pdf/1707.04242.pdf
https://github.com/nn4ir/nn4ir.github.io
Slides
https://github.com/nn4ir/nn4ir.github.io/tree/master/sigir2017/slides

Semantic matching:
methods for supervised, semi- and unsupervised learning for semantic matching.

Learning to Rank with Neural Networks:
Feature-based models for representation learning, ranking objectives and loss functions
and training a neural ranker under different levels of supervision.

Modeling user behavior with Neural Networks:
Probabilistic graphical models, Neural click models, and modeling biases using neural network will be described.

Generating Models:
The ideas on machine reading task, question answering, conversational IR, and dialogue systems will be covered.

****** Lexical vs Semantic matching
******* Traditional IR models
estimate relevance based on lexical matches of query terms in document.
******* Representation learning based models garner evidence of relevance from all document terms based on semantic matches with query.
_Both lexical and semantic matching are important and can be modelled with neural networks._

**** Learning to rank
shoelace : https://github.com/rjagerman/shoelace [Jagerman et al., 2017]

***** quickrank
QuickRank : http://quickrank.isti.cnr.it [Capannini et al., 2016]

Capannini, G., Lucchese, C., Nardini, F. M., Orlando, S., Perego, R., and Tonellotto, N. Quality versus efficiency in document scoring with learning-to-rank models. Information Processing & Management 2016.
https://www.sciencedirect.com/science/article/abs/pii/S0306457316301248

** Reference your chosen papers
/home/shane/dump/home/shane/notes2018/projects/ir-assignment-2/acmart-master/acmart.bbl

In your report you should outline the research questions and main contribution of each paper you
select. You should discuss how the papers you chose are related to each other. Finally, you should
formulate two new research questions in the area and discuss how you would address these.

bibliographystyle:unsrt
bibliography:refs.bib

* Preliminaries
** Background Knowledge
- Deep learning models :: are function approximators.

*** Search engine vs Database
  - _Relational Databases_ use a _B-Tree index_.
  - *Search engines* mostly use *inverted index*.q
  - _Relational Databases_ give you what you _asked for_.
  - *Search engines* give you what you *wanted*.

*** Terminology
+ _Indices_ :: = indexes. Indexes just sounds wrong to me.
+ _Model_ :: The *set of functions* that describe the relations between variables.

#+BEGIN_QUOTE
"Probabilistic and information theoretic methods are used to make results better anyway.
Compromises are made anyway. Query reformulation, drift, etc.
So it is just a natural progression to use NNs for some of these components? Am I right." -- A quote from myself.
#+END_QUOTE

** More Background Knowledge
*** The research works under the premise that
+ *Indices are models* (set of functions). For example,
  + B-Tree-Index :: $f: key \mapsto pos$
    - $pos$ is the position of a record, within a *sorted* array
  + Hash-Index :: $f: key \mapsto pos$
    - $pos$ is the position of a record, within an *unsorted* array
  + BitMap-Index :: indicates if a data record exists or not

*** A new term is introduced!
+ _*Learned Index*_ :: A deep-learning model with the function of an index structure.
                   Auto-/magestically/ synthesised.

* Overview
** The Argument of the Paper
*** The researchers _/hypothesise/_...
that *All* existing index structures *can* be replaced with learned indices.
+ Paper does not argue that you *should* necessarily.

  It's a novel approach to build indexes, complimenting existing work.

+  Specifically, a model can
   1. *Learn* the _sort order/structure_ of *keys*,
   2. and use this to *predict* the _position/existence_ of *records*.

*** They _/explore/_...
+ The *extent* to which learned models (including NNs) can replace traditional index for *efficient data access*.
*** They _/speculate/_...
- This could fundamentally change the way database systems are developed in the future.

** Investigations / Case studies
The studies performed in the paper are:
+ About evaluating learned models on *efficient data access*, the role of traditional indices.
+ Done on CPUs rather than G/TPUs for a fairer comparison with existing methods, despite new hardware being the biggest reason to use learned indices.

*** Theme 1: Can learned models speed up indices?
| tested for read-only analytical workloads | (The majority of this paper) |
| tested for write-heavy workloads          | (Briefly covered)            |

*** Theme 2: Can replacing individual components speed up indices?
| Study 1 / 3 | B-Tree                            | (Evaluated)       |
| Study 2 / 3 | Hash-index                        | (Evaluated)       |
| Study 3 / 3 | Bloom-filter                      | (Evaluated)       |
|             | other components (sorting, joins) | (Briefly covered) |

** Debunking the Myths
*** _Myths_ or soon to become myths
1. +Machine learning cannot provide the same semantic guarantees+.
   
   /Traditional/ indices largely *are already* /learned/ indices.
   - B-Trees _*predict*_ record position.
   - Bloom filter is a binary _*classifier*_ (like our Delta Rule network).
     It's a space-efficient probabilistic data structure. See: BitFunnel.
#+BEGIN_COMMENT
In BitFunnel: Revisiting Signatures for Search, a research paper from
Microsoft that came out in Aug, 2017, they use 
a Bloom filter to replace bit-signatures.

Bit-signatures represent the set of terms in each document as a fixed sequence of bits.

Bloom filters are reasonably space efficient and allow for fast set
membership, forming the basis for query processing.
#+END_COMMENT

2. +NNs thought of as being very expensive to evaluate+.
   - Huge _*benefits*_, especially on the next generation of hardware.

*** _Trends_ :BMCOL:B_block:
:PROPERTIES:
:BEAMER_col: 0.45
:BEAMER_env: block
:END:
+ GPUs and TPUs in phones

  The main reason to adopt learned indices (page 4).
+ Scaling NN trivial. Cost = 0.

*** _Benefits_ for databases :BMCOL:B_block:
:PROPERTIES:
:BEAMER_col: 0.45
:BEAMER_env: block
:END:
+ Remove the +branch-heavy index structures+ and add *Neural Networks*

#+BEGIN_COMMENT
Every CPU has powerful SIMD capabilities

Many laptops and mobile phones will soon have a Graphics Processing Unit
(GPU) or Tensor Processing Unit (TPU).

It is also reasonable to speculate that CPU-SIMD/GPU/TPUs will be
increasingly powerful as it is much easier to scale the restricted set
of (parallel) math operations used by neural-nets than a general purpose
instruction set.

High cost to execute a neural net might actually be negligible in the
future.

Nvidia and Google’s TPUs are already able to perform thousands if not
tens of thousands of neural net operations in a single cycle.

GPUs will improve 1000× in performance by 2025, whereas Moore’s law for
CPU essentially is dead.

By replacing branch-heavy index structures with neural networks,
databases can benefit from these hardware trends.
#+END_COMMENT

** Results and Conclusions sneak peak
*** Results
1. *Learned* indices /can/ be 70% *faster* than cache-optimized B-Trees while *saving* an order-of-magnitude in *memory*.

   - Tested over several real-world datasets.

*** Conclusions
1. *Replacing components* of a data management system with /*learned*/ models has *far-reaching* implications.

   - This work only provides a *glimpse* of what might be possible...

* Introduction
** "Traditional" Index Structures
*** Some examples :BMCOL:B_block:
:PROPERTIES:
:BEAMER_col: 0.70
:BEAMER_env: block
:END:
/Covered in this paper by 3 separate studies:/
1. B-Trees
   + Great for *range* requests (retrieve all in a..b)
2. Hash-Maps
   + *key*-based lookups
3. Bloom-filters
   + Set membership
   + May give false positives, but no false negatives

*** Solidly built :BMCOL:B_block:
:PROPERTIES:
:BEAMER_col: 0.30
:BEAMER_env: block
:END:
+ Highly Optimised
  - Memory
  - Cache
  - CPU
+ Assume worst case

#+BEGIN_COMMENT
Because of the importance of indexes for database systems and many other applications, they have been extensively tuned over the past decades to be more memory, cache and/or CPU efficient 
#+END_COMMENT

*** It works because...
+ *Knowing* the exact data distribution *enables optimisation* of the index.

  ...But then we... /must/ know. But we don't always.

#+BEGIN_COMMENT
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+END_COMMENT

** Benefits of replacing B-Trees with Learned Indices
*** Benefits of replacing B-Trees with Learned Indices
1. B-Tree lookup $O(\log_n) \Longrightarrow O(n)$ (if SLM)
   + Simple Linear [Regression] Model :: predictor,  1 mul, 1 add...
#+BEGIN_COMMENT
Key itself can be used as an offset, sometimes.
If the goal would be to build a highly tuned system to store and query fixed-length records with continuous integer keys (e.g., the keys 1 to 100M), one would not use a conventional B-Tree index over the keys since the key itself can be used as an offset, making it an
O(1) rather than O(log n) operation to look-up any key or the beginning
of a range of keys. Similarly, the index memory size would be reduced
from O(n) to O(1).
#+END_COMMENT
1. ML accelerators (GPU/TPU)
   If the entire learned index can fit into GPU's memory, that's 1M NN ops every 30 cycles with current technology.
2. Mixture of Models (builds upon Jeff's paper from last year)
   ReLU at top, learning a wide range of complex data distributions.
   SLRM at the bottom because they are inexpensive.
   Or use B-Trees at the bottom stage if the data is hard to learn.
   
#+BEGIN_COMMENT
Non-monotonically increasing models.
#+END_COMMENT

* Case Studies
** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
Replacing a B-tree with a *Learned* _[Range] *Index*_ [Model].
*** Theory
+ $\therefore$ *B-Tree* $\approx$ Regression Tree $\approx$ CDF $\equiv$ *Learned Range Index*.
*** Plan
+ Experiment with a Naïve Learned Index
  ... to see how bad it is.
+ Experiment with a much better Learned Index, the _RM-Index_.

** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
#+BEGIN_COMMENT
$\equiv$
#+END_COMMENT
Why can we replace B-Trees with DL again?
#+BEGIN_COMMENT
An index ~is-a~ model. B-Tree ~is-a~ model. Range Index Model ~is-a~ CDF Model $F_X(x) = P(X \leq x)$.
Cumulative density function, of X (a variable)
Distribution function, of X
    $F_X(x) = P(X \leq x)$
	Evaluated at x (specific value), it is the probability that X will take a value less than or equal to x.
#+END_COMMENT
*** B-Tree ~is-a~ model
 + B-Tree-Index :: $f: key \mapsto pos$
   - $pos$ is the position of a record, within a *sorted* array
*** B-Tree $\approx$ /Regression Tree/
 + _Regression Tree_ :: A decision tree with $\mathbb{R}$ targets.
   - Maps a key to a position with a min and max error.
#+BEGIN_COMMENT
+ max/ min error :: before re-training or re-balancing for new data
#+END_COMMENT
*** Range Index Model ~is-a~ Cumulative Density Function (CDF)
#+BEGIN_QUOTE
A model which predicts the position given a key inside a sorted array effectively approximates a CDF (page 5).
#+END_QUOTE

+ $\therefore$ *B-Tree* $\approx$ Regression Tree $\approx$ CDF $\equiv$ *Learned Range Index*.

** Study 1 of 3: +B-Tree+ $\Rightarrow$ RT/RIM $\Rightarrow$ CDF $\Rightarrow$ Learned R.I.
#+BEGIN_COMMENT
+ Implications
  1. Indexing literally requires learning a data distribution.
     A B-Tree learns the data distribution by building a regression tree.
     A linear regression model would learn the data distribution by minimising the squared error of a linear function.
  2. Estimating the distribution for a data set is a well known problem and learned indexes can benefit from decades of research.
  3. Learning the CDF plays a key role in optimising other types of index structures and potential algorithms.
#+END_COMMENT
*** Analogs
+ Rebalanced vs Retrained
#+BEGIN_COMMENT
B-Tree only provides error guarantee over stored data, not new data.
#+END_COMMENT

  $\therefore$ min/max error guarantee only needed for training.

*** Cumulative Density Function (CDF)
$F_X(x) = P(X \leq x)$

A range index needs to be able to provide:
+ point queries $\checkmark$
+ range queries, sort order(records) $\equiv$ sort order(sorted look-up keys)) $\checkmark$
+ guarantees on min-/max error.

CDF is good to go. It can be used as our Learned Range Index.
*** $\therefore$
Can replace index with other models including DL, so long as min and max error are similar to b-tree.


** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
*** Experiment 1.1 - Naïve Learned Index with TensorFlow
+ Objective :: Evaluate to study the technical requirements to replace B-Trees.
+ Architecture ::
  + Two-layer fully conneted neural network (32:32).
  + 32 neurons/units per layer.
  + ReLU activation function.
  + Input features :: The timestamps of messages from web server logs
  + Labels :: The positions of the messages (actual line number?)
  + Optimisation goal :: Is not /simply/ error minimisation. Min-/max error
  #+BEGIN_COMMENT
  Indexing only needs a best guess of position.
  More important are guarantees of min and max error.
#+END_COMMENT
+ Purpose :: Build secondary index over timestamps. Test performance.


** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
*** Critique
This is a very naïve learned index, and that's how we want it. The researchers want to see how much faster a B-Tree is than a *naïve* neural network substitution. The answer is 300x faster.

+ ReLU activation function :: $f(x) = max(0, x)$

The ReLU activation function is _the new sigmoid_ in that it's now the go-to activation function for deep learning.

It's typically used for hidden layers as it avoids vanishing gradient problem, yet we don't have a hidden layer. It's just a line. It's so basic, it's perfect.

Also, the researchers are after a sparse representation, matching one key to one position, so this property of the ReLU makes it an even better candidate.

I assume that 32 neurons are used because that is the max string length of the timestamp / record position.

#+BEGIN_COMMENT
sigmoid:
product of many smaller than 1 values goes to zero very quickly.
Since the state of the art of for Deep Learning has shown that more layers helps a lot, then this disadvantage of the Sigmoid function is a game killer. You just can't do Deep Learning with Sigmoid.
#+END_COMMENT

#+BEGIN_COMMENT
Input neurons are just inputs. They do not have a bias or an activation function. I don't think Relu is being used on the input layer.

The problem with ReLU is that some gradients can be fragile during training and can die.
It can cause a weight update which will make it never activate on any data point again.
Simply saying that ReLU could result in Dead Neurons.
#+END_COMMENT

#+BEGIN_COMMENT
Leaky ReLU
This is a step away from what we want. It's less naïve and we want naïveness.

Leaky ReLu could be used to fix the problem of dying neurons. It introduces a small slope to keep the updates alive.
#+END_COMMENT
** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
*** Experiment 1.1 - Results
The researchers came to these findings:
+ B-Trees are 2 orders of magnitude faster. Tensorflow is designed for larger models. Lots of overhead with Python.
+ _A *single* neural network requires significantly more space and CPU time for the *last mile* of error minimisation_.
+ B-Trees, or decision trees in general, are really good in overfitting the data (adding new data after balancing) with a *few* operations. They just divide up the space cheaply, using an if-statement.
+ Other models can be significantly more efficient to approximate the general shape of a CDF.
  + So models like NNs might be more CPU and space efficient to narrow down the position for an item from the entire data set to a region of thousands.
  + But usually requires significantly more space and CPU time for the last mile.

These ideas are taken into account when designing the next model, the *RM-Index*.

#+BEGIN_COMMENT
From a top-level view, the CDF function appears very smooth and regular.
However, if one zooms in to the individual records, more and more
irregularities show; a well known statistical effect. Many data sets
have exactly this behavior: from the top the data distribution appears
very smooth, whereas as more is zoomed in the harder it is to
approximate the CDF because of the “randomness” on the individual level.
#+END_COMMENT

#+BEGIN_COMMENT
Polynomial regression can be solved in a 'least squares' sense.
#+END_COMMENT

#+BEGIN_COMMENT
Maybe keep this for 420.

3. The typical ML optimization goal is to minimize the average error.

   However, for indexing, where we not only need the best guess where the item might be but also to actually find it, the min- and max-error as discussed earlier are more important.

   The min-error for a b-tree is 0 and the max-error is the page size.
   We only need strong guarantees for these values with learned indices.
   
4. B-Trees are extremely cache-efficient as they keep the top nodes always in cache and access other pages
if needed. However, other models are not as cache and operation efficient. For example, standard neural
nets require all weights to compute a prediction, which has a high cost in the number of multiplications
and weights, which have to brought in from memory.
#+END_COMMENT

** Study 1 of 3: Learned Range Index [Model] $\approx$ B-Tree

*** Challenges to replacing B-Trees
1. Main challenge: balance model *complexity* with *accuracy*.
#+BEGIN_COMMENT
Remember SLM below.
#+END_COMMENT
2. *Bounded cost* for inserts and lookups, taking advantage of the *cache*.
3. Map keys to pages (*memory or disk?*)
4. Last mile accuracy.
   This is the main reason why the Naïve Learned Model was so slow.
   Overcome by using the Recursive Model (RM) Index.

**** New terms
+ Last mile accuracy
#+BEGIN_COMMENT
Reducing the min-/max-error in the order of hundreds from 100M records using a single model is very hard.

At the same time, reducing the error to 10k from 100M (a precision gain of 100*100 = 10,000) to replace the first 2 layers of a B-Tree through a model is much easier to achieve even with simple models.

Reducing the error from 10k to 100 is a simpler problem as the model can focus only on a subset of the data.
#+END_COMMENT
** Study 1 of 3: Learned Range Index [Model] $\approx$ B-Tree
*** Recursive Model (RM) Index
Also known as the Recursive Regression Model.

One of the key contributions of this research paper.

A hierarchy of models.

At each stage the model takes the key as an input and based on it picks another model, until the final stage predicts the position.

Each prediction as you go down the hierarchy is picking an expert that has better knowledge about certain keys.

Solves the 'Last mile accuracy' problem.
#+BEGIN_COMMENT
Because it divides the space into smaller sub-ranges like a B-Tree/decision tree. Fewer number of operations towards the end.
#+END_COMMENT

#+BEGIN_COMMENT
Inspired by the mixture of experts work.

One way to think about the different models is that each model makes a prediction with a certain error about the position for the key and that the prediction is used to select the next model.
#+END_COMMENT

#+BEGIN_COMMENT
Because there is no search process between stages.

5. Some may return positions outside of min-max error range, if lookup key doesnt exist in the set.
#+END_COMMENT

** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
*** Experiment 1.2 - Hybrid Recursive Model Index
+ Method ::
  + n stages, n models per stage = hyperparameters
  + Each net
    + 0 to 2 fully conneted hidden-layers
    + Up to 32 neurons/units per layer
  + ReLU activation functions
  + B-Trees.
  + Input features :: The timestamps of messages from web server logs
  + Labels :: The positions of the messages (actual line number?)
  + Datasets :: Blogs, Maps, web documents, lognormal (synthetic)
  + Optimisation goal :: Is not /simply/ error minimisation.
  + After training, the index is optimised by replacing NN models with B-Trees if absolute min-/max- error is above a predefined threshold value.
+ Conclusions ::
  + Allow use to bound the worst case performance of learned indexes to the performance of B-Trees.

  #+BEGIN_COMMENT
  Indexing only needs a best guess of position.
  More important are guarantees of min and max error.
#+END_COMMENT

** Study 1 of 3: +B-Tree+ $\Rightarrow$ Learned Range Index [Model]
*** Results of Experiment 1.2

Was the data used obtained ethically? Who knows.

* Testing
+ They developed what they call the 'Learning Index Framework', an index synthesis system.
  It accelerates the process of index synthesis and testing.

* Aim of review
** Questions
1. What is the specific problem or topic that this research addresses?
   1. Optimisation of an index requires *knowledge* of the data distribution. There is no guarantee of this. But it can be learned.
   2. Learned indices provide new ways to further optimise search engines.

2. If the paper presents a new network, algorithm, or technique, how does it work?
   Is it suited to the task?

   + A new model architecture, the Recursive Regression Model

     Task: A substitute for a B-Tree.

     Inspired by work done in the paper "Outrageously Large Neural Networks".

     Constitution:
     Build a hierarchy of models.
     At each stage the model takes the key as an input and based on it picks another model, until the final stage predicts the position.

     Each model makes a prediction with a certain error about the position for the key and that the prediction is used to select the next model.

     Recursive Model Indices are *not trees*.

     The architecture divides the space into smaller sub-ranges like a B-tree/decision tree to make it easier to achieve to required last-mile accuracy with a fewer number of operations.

   + Is it suited to the task?
     The model divides the space into smaller sub-ranges like a B-Tree to make it easier to achieve the required "last mile" accuracy with fewer operations.
     This solves one of the aformentioned complications of replacing a B-Tree.

     The entire index can be represented as a sparse matrix-multiplication for a TPU/GPU.

   
   Has it been well tested, and does it really work as claimed? What are the limitations?
   1. This could change the way database systems are developed.

3. What are Innovations

4. *Learned* indices /can/ be 70% *faster* than cache-optimized B-Trees while *saving* an order-of-magnitude in *memory*.

   - Tested over several real-world datasets.

5. Did they choose the architecture - why or why not?
Is it clearly described (all parameters, settings etc.)?
What strengths and/or weaknesses of the NN approach does it illustrate?


• Is the paper well structured and well written?

* Evaluation
*** Was the paper well organised?
It is well structured and well written.
*** Problem and solution :BMCOL:B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
+ problem :: Real world data does not perfectly follow known patterns. Specialised solutions expensive.
+ solution :: ML. Learn the model -> Synthesise specialised index. Low cost.
*** Strengths and/or weaknesses of the NN approach
The paper illustrated that...
*** Did they choose the right architectures? Why or why not?
Is it clearly described (all parameters, settings etc.)?
** Own Questions
*** Paper

*** Research question defined?
What is the research question?

*** Generalization
Does the study allow generalization?
*** Limitations



*** Consistency
The discussion and conclusions should be consistent with the study’s results.

Results
in accordance with the researcher’s expectations
not in accordance.

Do the authors of the article you hold in hand do the same?

*** Ethicsucture